import requests
import os
from dotenv import load_dotenv

load_dotenv()

def explain_question(question: str, prompt_mode: str = "simple") -> str:
    if prompt_mode == "simple":
        prompt = f"è¯·å°†è¿™é“é¢˜ç›®ä¸­éš¾æ‡‚çš„è¯è¯­æ›¿æ¢ä¸ºä¸­å›½å…­å¹´çº§å°å­¦ç”Ÿèƒ½ç†è§£çš„è¯´æ³•ï¼Œä»…æ›¿æ¢è¯è¯­ï¼Œä¸è¦è§£é‡Šé¢˜ç›®æœ¬èº«ï¼š{question}"
    elif prompt_mode == "step":
        prompt = f"è¯·ä¸€æ­¥æ­¥å¼•å¯¼ä¸­å›½å…­å¹´çº§å°å­¦ç”Ÿæ€è€ƒè¿™é“é¢˜ã€‚æ¯ä¸€æ­¥æœ€å¤šä¸€å¥è¯ï¼Œæ–‡å­—å¿…é¡»ç®€çŸ­æ¸…æ¥šï¼Œä½¿ç”¨ç®€å•è¯è¯­ã€‚æœ€å¤šå†™ 4 æ­¥ï¼Œæ¯æ­¥ç”¨â€œç¬¬1æ­¥â€ã€â€œç¬¬2æ­¥â€å¼€å¤´ã€‚ä¸è¦ç›´æ¥å†™å‡ºç­”æ¡ˆæˆ–è®¡ç®—ç»“æœï¼š{question}"
    else:
        prompt = f"è¯·è§£é‡Šè¿™é“é¢˜ç›®ï¼š{question}"

    url = os.getenv("GPT_API_URL")
    api_key = os.getenv("GPT_API_KEY")

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    payload = {
        "model": "gpt-3.5-turbo",
        "messages": [{"role": "user", "content": prompt}]
    }

    try:
        print("ğŸ“¡ æ­£åœ¨è°ƒç”¨ GPT æ¥å£", flush=True)
        print("ğŸŒ è¯·æ±‚åœ°å€:", url, flush=True)
        print("ğŸ“ è¯·æ±‚å¤´:", headers, flush=True)
        print("ğŸ“¦ è¯·æ±‚ä½“:", payload, flush=True)
        response = requests.post(url, json=payload, headers=headers)
        response.raise_for_status()
        data = response.json()
        print("ğŸ§  GPT è§£é‡Šå†…å®¹:", data["choices"][0]["message"]["content"], flush=True)
        return data["choices"][0]["message"]["content"]
    except Exception as e:
        if 'response' in locals():
            print("âŒ å“åº”å†…å®¹:", response.text, flush=True)
        return f"è°ƒç”¨å¤±è´¥ï¼š{str(e)}"
